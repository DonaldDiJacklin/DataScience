{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res(X,mu, sigma, Pi):\n",
    "#     print(X.shape)\n",
    "#     print(mu.shape)\n",
    "#     print(sigma.shape)\n",
    "#     print(Pi)\n",
    "    d = Pi*sp.multivariate_normal.pdf(X, mu, sigma)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = io.loadmat('shuttle.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TTsplit(matrix, train = .7):\n",
    "    #     This function's purpose is to split a given matrix\n",
    "    #     into three parts: train, test, and validate. The \n",
    "    #     train parameter is the percentage of the data that\n",
    "    #     goes into training 70% by default. The val parameter\n",
    "    #     determines how much goes into the validation set\n",
    "    #     15% by default. The rest of the data goes into\n",
    "    #     the test set.\n",
    "    \n",
    "#     The following is needed to perform the operations\n",
    "#     in the calculations in here.\n",
    "    import numpy as np\n",
    "    # The following does some common sense things like\n",
    "    # telling you that train and val need to add up to less\n",
    "    # than 1.\n",
    "\n",
    "    if(train > .99):\n",
    "        print(\"Splitting failed. Please make sure that train is less than .99 so that test and val have enough data.\")\n",
    "        return 0\n",
    "    \n",
    "#     These two things calculate the subset lengths that \n",
    "#     are needed for the subsetting.\n",
    "    splitnum = int(len(matrix[:,0])*train)\n",
    "    np.random.shuffle(matrix)\n",
    "\n",
    "#     The next three separate the data into the three sets\n",
    "#     using the splitnums from above.\n",
    "    Train = matrix[0:splitnum,]\n",
    "    Test = matrix[splitnum:,]\n",
    "    return Train, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullX = np.array(full['X'], dtype = float)\n",
    "fullY = full['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = TTsplit(np.column_stack((fullX,fullY)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = train[np.where(train[:,-1] == 0)[0],:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49097"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fullX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "k = 14\n",
    "M = np.empty((k,Xtrain.shape[1]))\n",
    "sigma = np.empty((Xtrain.shape[1],Xtrain.shape[1],k))\n",
    "M = Xtrain[np.random.choice(Xtrain.shape[0],k)].astype(np.float64)\n",
    "for i in range(k):\n",
    "    r = np.random.randn(9,9)*500\n",
    "    sigma[:,:,i] = r.T@r\n",
    "Pi = np.ones(k)/k\n",
    "for i in range(40):\n",
    "    print(i)\n",
    "    D = np.empty((len(Xtrain),k))\n",
    "    for i in range(0,k):\n",
    "        D[:,i] = np.array(res(Xtrain, M[i,], sigma[:,:,i], Pi[i]), dtype = float)\n",
    "    D = D/np.sum(D, axis = 1).reshape(-1,1)\n",
    "    Pi = np.mean(D,axis = 0)\n",
    "    for i in range(0,k):\n",
    "        M[i,] = np.array(np.sum(D[:,i].reshape(-1,1)*Xtrain, axis = 0)/np.sum(D[:,i]).reshape(-1,1), dtype = float)\n",
    "        sigma[:,:,i] = (D[:,i].reshape(-1,1)*(Xtrain - M[i,])).T@(Xtrain - M[i,])/np.sum(D[:,i]).reshape(-1,1) + .00001*np.eye(fullX.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "newD = np.empty((len(train[:,:-1]),k))\n",
    "for i in range(0,k):\n",
    "    newD[:,i] = np.array(res(train[:,:-1], M[i,], sigma[:,:,i], Pi[i]), dtype = float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Following Calculates The Number of Misclassified Points in The Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[:,-1])-np.sum((np.sum(newD, axis = 1)<1e-17).reshape(-1,1) == train[:,-1].reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "newestD = np.empty((len(test[:,:-1]),k))\n",
    "for i in range(0,k):\n",
    "    newestD[:,i] = np.array(res(test[:,:-1], M[i,], sigma[:,:,i], Pi[i]), dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test[:,-1])-np.sum((np.sum(newestD, axis = 1)<1e-17).reshape(-1,1) == test[:,-1].reshape(-1,1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
